# TODO ‚Äî AI Person (B·ªô N√£o Th·ª© 2)

> **Version:** v0.1.2
> **Last Updated:** 2026-02-21
> **Status:** Code refactored to 5-mode ‚Üí docs synced ‚Üí manual end-to-end test next

---

## üî• P0 ‚Äî Ph·∫£i l√†m ngay (tr∆∞·ªõc khi d√πng th·ª±c t·∫ø)

- [ ] **Setup `.env`** ‚Äî copy `.env.example` ‚Üí `.env`, ƒëi·ªÅn `OPENAI_API_KEY`
- [x] **‚úÖ Fix REFLECT epistemic conflict:**
  - [x] `prompts.py`: ƒë·ªïi `REFLECT.can_use_external_knowledge = True` ‚Üí `False`
  - [x] `prompts.py`: x√≥a external mention trong REFLECT instruction
  - [x] `service.py`: ƒë·ªïi sang EXPAND-only, x√≥a `MIN_CONTEXT_TOKENS` + token-threshold
  - [x] `service.py`: thay b·∫±ng mode-based rule (`policy.can_use_external_knowledge`)
- [x] **‚úÖ Upgrade to 5-mode:**
  - [x] `prompts.py`: th√™m SYNTHESIZE + EXPAND v√†o `MODE_INSTRUCTIONS` + `MODE_POLICIES`
  - [x] `mode_controller.py`: `VALID_MODES` = 5 modes, raises `InvalidModeError`
  - [x] `schemas/query.py`: `ModeEnum` v·ªõi 5 values + `content_type` validator
  - [x] `ranking.py`: 5-mode weights per DATA_DESIGN 7.2.1
  - [x] `exceptions/handlers.py`: `InvalidModeError` (422)
  - [x] `prompt_builder.py`: docstring updated to 5 modes
- [x] **Ch·∫°y Docker** ‚Äî `docker compose up -d` ‚úÖ
- [x] **Ch·∫°y migration** ‚Äî `alembic upgrade head` ‚úÖ ‚Äî all 7 indexes created
  - `idx_memory_embedding` (HNSW)
  - `idx_memory_created_at`
  - `idx_memory_content_type`
  - `idx_memory_metadata` (GIN)
  - `idx_memory_checksum` (UNIQUE)
  - `idx_embedding_jobs_status`
  - `idx_memory_embedding_model`
- [ ] **End-to-end test th·ªß c√¥ng:**
  - [ ] `POST /api/v1/memory` ‚Üí insert th√†nh c√¥ng
  - [ ] Check `embedding_jobs` status = `pending`
  - [ ] Ch·∫°y worker: `python -m workers.run_embedding`
  - [ ] Verify `memory_records.embedding != NULL`
  - [ ] Check `embedding_jobs` status = `completed`
  - [ ] `POST /api/v1/search` ‚Üí tr·∫£ k·∫øt qu·∫£ ƒë√∫ng
  - [ ] `POST /api/v1/query` v·ªõi `mode=RECALL` ‚Üí tra ƒë√∫ng
  - [ ] `POST /api/v1/query` v·ªõi `mode=SYNTHESIZE` ‚Üí t·ªïng h·ª£p memory
  - [ ] `POST /api/v1/query` v·ªõi `mode=REFLECT` ‚Üí nh·∫≠n di·ªán evolution
  - [ ] `POST /api/v1/query` v·ªõi `mode=CHALLENGE` ‚Üí verify `external_knowledge_used=false`
  - [ ] `POST /api/v1/query` v·ªõi `mode=EXPAND` ‚Üí verify `external_knowledge_used=true`

---

## üü° P1 ‚Äî N√™n l√†m s·ªõm

- [x] **5-Mode code migration** (completed)
  - [ ] üî¥ Update `_EXTERNAL_KNOWLEDGE_ALLOWED_MODES` ‚Üí `{"EXPAND"}` in `reasoning/service.py`
  - [ ] üî¥ Remove `MIN_CONTEXT_TOKENS` + token-threshold logic in `reasoning/service.py`
  - [ ] üî¥ Replace token-threshold conditional with `if mode == "EXPAND"` in `reasoning/service.py`
  - [ ] Add SYNTHESIZE + EXPAND weights to `_MODE_WEIGHTS` in `retrieval/ranking.py`
  - [ ] Update `personalities/default.yaml` with SYNTHESIZE + EXPAND prompts
  - [ ] Implement `metadata_filter` ‚Üí SQL JSONB containment (`@>`) in `retrieval/search.py`
  - [ ] Add `content_type` enum validation to `schemas/search.py`
  - [ ] Add `INVALID_MODE` error to `exceptions/handlers.py`
- [ ] **Phase 0: Behavior Freeze**
  - [ ] Ch·ªët system prompt final trong `personalities/default.yaml`
  - [ ] Test 30 l∆∞·ª£t chat tay, verify AI gi·ªØ ƒë√∫ng nh√¢n c√°ch
  - [ ] Verify mode RECALL / REFLECT / CHALLENGE ho·∫°t ƒë·ªông ƒë√∫ng
  - [ ] Document k·∫øt qu·∫£ v√†o `docs/BEHAVIOR_FREEZE.md`
- [ ] **Verify epistemic boundary th·ª±c t·∫ø:**
  - [ ] REFLECT v·ªõi 0 memory ‚Üí `external_knowledge_used=true`
  - [ ] REFLECT v·ªõi nhi·ªÅu memory d√†i (>800 tokens) ‚Üí `external_knowledge_used=false`
- [ ] **C·∫≠p nh·∫≠t GitHub repo URLs trong `CHANGELOG.md`** (khi c√≥ remote)
- [ ] **C·∫≠p nh·∫≠t Project Context** trong `PROMPT.md` skill:
  - `Project name:` AI Person ‚Äî B·ªô N√£o Th·ª© 2
  - `Current version:` v0.1.1
  - `Tech stack:` FastAPI, SQLAlchemy 2.0, asyncpg, pgvector, OpenAI
  - `Current progress:` All phases complete, pending first real run

---

## üîµ P2 ‚Äî Backlog / V2

- [ ] **`local_adapter.py`** ‚Äî LM Studio / Ollama local model adapter (V2)
- [ ] **Summary persistence** ‚Äî LLM-generated summary v·ªõi user approval flow (V2)
  - `is_summary=true`, `metadata.parent_id`, `metadata.generated_by="system"`
  - M·∫∑c ƒë·ªãnh excluded kh·ªèi retrieval
- [ ] **Chunking t·ª± ƒë·ªông** ‚Äî auto-chunk PDF / article d√†i tr∆∞·ªõc khi insert (V2)
- [ ] **Partition strategy** ‚Äî khi > 1M records, partition `memory_records` theo th√°ng
- [ ] **Re-embed pipeline** ‚Äî khi ƒë·ªïi embedding model, re-embed to√†n b·ªô records (V2)
- [ ] **Backup strategy** ‚Äî cron daily backup, verify checksum integrity

---

## ‚úÖ ƒê√£ ho√†n th√†nh

- [x] **Phase 1: Foundation** ‚Äî DB, ORM (3 tables + 7 indexes), migration, session, config, logging, exceptions
- [x] **Phase 2: Memory Infrastructure** ‚Äî MemoryService, EmbeddingWorker, repository, embedding adapters
- [x] **Phase 3: Retrieval Engine** ‚Äî RetrievalService, ranking formula (mode-aware), diversity guard, TokenGuard
- [x] **Phase 4: Reasoning Layer** ‚Äî ReasoningService, ModeController, PromptBuilder, LLM adapters
- [x] **Phase 5: API Layer** ‚Äî memory / search / query endpoints, deps DI, main.py, CORS, correlation ID middleware
- [x] **Documentation** ‚Äî README.md, .env.example, docker-compose.yml, personalities/default.yaml
- [x] **Fix #1: Epistemic Boundary** ‚Äî token-threshold (800) replaces count-based rule in code + docs
- [x] **Fix #2: Index count** ‚Äî 5 ‚Üí 7, named in IMPLEMENTATION_PLAN checklist
- [x] **Fix #3: Migration path** ‚Äî `alembic init alembic` corrected to `app/db/migrations` in DATA_DESIGN
- [x] **Fix #4: is_summary filter** ‚Äî `AND is_summary = false` added to retrieval SQL in DATA_DESIGN
- [x] **Fix #5: Summary policy** ‚Äî V1 Strict: LLM kh√¥ng persist, section 8.2 drop-only
- [x] **Worker concurrency** ‚Äî `SELECT FOR UPDATE SKIP LOCKED` in `get_pending_jobs()`
- [x] **CHANGELOG.md** ‚Äî created, v0.1.0 + v0.1.1 documented
- [x] **TODO.md** ‚Äî this file
- [x] **API_DOCS.md** ‚Äî full API reference (5 endpoints, schemas, modes, error codes, cURL examples)
- [x] **OpenClaw analysis** ‚Äî applied doc recommendations (Memory-First Principle, engagement V2, etc.)
- [x] **5-Mode Design** ‚Äî docs migration: RECALL/SYNTHESIZE/REFLECT/CHALLENGE/EXPAND
  - `idea.md`: full rewrite with 5-mode ideal + architecture flow
  - `PROJECT_STRUCTURE.md`: sections 2.1, 5, Epistemic Boundary, Policy Guard
  - `API_DOCS.md`: modes table, cURL examples
  - `IMPLEMENTATION_PLAN.md`: Phase 4 checklist + test scenarios
  - Retired: ANALYZE, TEMPORAL_COMPARE ‚Üí merged into SYNTHESIZE, REFLECT
  - Retired: token-threshold (800) ‚Üí mode-based (EXPAND = external ON)
