# AI Person â€” Bá»™ NÃ£o Thá»© 2

> **Personal Memory-First AI System** â€” Version 0.1.0

A production-grade personal AI that stores your thinking history and reasons over it. Not a chatbot. Not a RAG demo. A long-term memory infrastructure designed to live alongside you for 5â€“10 years.

---

## ğŸ— Architecture

```
API Layer (FastAPI)
    â†“
Memory Infrastructure   â†’   Retrieval Engine   â†’   Reasoning Layer
(save, checksum, embed)     (semantic search)       (mode + prompt + LLM)
    â†“                              â†“                       â†“
              PostgreSQL 16 + pgvector (HNSW)
```

**3 modes:** `RECALL` (fetch what I wrote) Â· `REFLECT` (synthesize patterns) Â· `CHALLENGE` (find contradictions)

---

## âš¡ Quick Start

### 1. Prerequisites

- Python 3.11+
- Docker + Docker Compose
- OpenAI API key

### 2. Setup

```bash
# Clone and enter
cd AI_Person

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate      # Windows
# source venv/bin/activate   # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Configure environment
copy .env.example .env
# Edit .env: set OPENAI_API_KEY
```

### 3. Start Database

```bash
docker compose up -d
```

### 4. Run Migrations

```bash
alembic upgrade head
```

### 5. Start API Server

```bash
uvicorn app.main:app --reload --port 8000
```

### 6. Start Embedding Worker (separate terminal)

```bash
python -m workers.run_embedding
```

API docs available at: `http://localhost:8000/docs` (only when `DEBUG=true`)

---

## ğŸ”Œ API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/memory` | Save a new memory |
| `GET` | `/api/v1/memory/{id}` | Get memory by ID |
| `PATCH` | `/api/v1/memory/{id}/archive` | Soft-archive (selective forgetting) |
| `POST` | `/api/v1/search` | Semantic search |
| `POST` | `/api/v1/query` | Reasoning query |
| `GET` | `/health` | Health check |

### Save Memory

```bash
curl -X POST http://localhost:8000/api/v1/memory \
  -H "Content-Type: application/json" \
  -d '{
    "raw_text": "HÃ´m nay tÃ´i nháº­n ra ráº±ng momentum trong ML khÃ´ng chá»‰ lÃ  ká»¹ thuáº­t mÃ  lÃ  tÆ° duy.",
    "content_type": "reflection",
    "importance_score": 0.8
  }'
```

### Search

```bash
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "suy nghÄ© vá» machine learning",
    "limit": 10
  }'
```

### Reasoning Query

```bash
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "TÆ° duy cá»§a tÃ´i vá» AI thay Ä‘á»•i tháº¿ nÃ o theo thá»i gian?",
    "mode": "REFLECT"
  }'
```

---

## ğŸ—‚ Project Structure

```
AI_Person/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # HTTP endpoints (no business logic)
â”‚   â”œâ”€â”€ core/             # Personality, prompts, token guard
â”‚   â”œâ”€â”€ db/               # SQLAlchemy models + Alembic migrations
â”‚   â”œâ”€â”€ exceptions/       # Custom exception classes + handlers
â”‚   â”œâ”€â”€ llm/              # LLM + Embedding adapters (swappable)
â”‚   â”œâ”€â”€ logging/          # Structured JSON logger
â”‚   â”œâ”€â”€ memory/           # Save + checksum + embedding job creation
â”‚   â”œâ”€â”€ reasoning/        # Mode controller + prompt builder + orchestrator
â”‚   â”œâ”€â”€ retrieval/        # Semantic search + ranking
â”‚   â”œâ”€â”€ schemas/          # Pydantic request/response models
â”‚   â”œâ”€â”€ config.py         # Settings (all env vars)
â”‚   â”œâ”€â”€ deps.py           # Dependency injection
â”‚   â””â”€â”€ main.py           # FastAPI app entry point
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ run_embedding.py  # Background embedding CLI
â”œâ”€â”€ personalities/
â”‚   â””â”€â”€ default.yaml      # AI personality config
â”œâ”€â”€ docs/                 # Architecture documentation
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env.example
```

---

## âš™ï¸ Environment Variables

| Variable | Default | Description |
|---|---|---|
| `DATABASE_URL` | `postgresql+asyncpg://...` | PostgreSQL connection string |
| `OPENAI_API_KEY` | *(required)* | OpenAI API key |
| `EMBEDDING_MODEL` | `text-embedding-3-small` | Embedding model name |
| `LLM_MODEL` | `gpt-4.1-mini` | LLM model name |
| `MAX_CONTEXT_TOKENS` | `3000` | Token budget for memory context |
| `LOG_LEVEL` | `INFO` | Log level |
| `DEBUG` | `false` | Enable debug mode + API docs |
| `EMBEDDING_WORKER_INTERVAL_SECONDS` | `5` | Worker polling interval |

---

## ğŸŒ¿ Git Workflow

```
main                    â† production-ready
â”œâ”€â”€ develop             â† integration
â”‚   â”œâ”€â”€ feature/phase1-foundation
â”‚   â”œâ”€â”€ feature/phase2-memory
â”‚   â”œâ”€â”€ feature/phase3-retrieval
â”‚   â”œâ”€â”€ feature/phase4-reasoning
â”‚   â””â”€â”€ feature/phase5-polish
```

---

## ğŸ“š Documentation

| Doc | Description |
|---|---|
| [PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md) | Architecture philosophy + data flow |
| [DATA_DESIGN.md](docs/DATA_DESIGN.md) | DB schema, indexes, retrieval SQL |
| [CODEBASE_STRUCTURE.md](docs/CODEBASE_STRUCTURE.md) | File responsibilities |
| [IMPLEMENTATION_PLAN.md](docs/IMPLEMENTATION_PLAN.md) | Phase roadmap + checklists |

---

## ğŸ“¦ Version

Current: **v0.1.0** â€” Phase 1 Foundation (Database + Memory Infrastructure)
